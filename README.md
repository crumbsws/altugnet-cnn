ğŸ§  Number Image Classifier & Adversarial Attack Generator

This repository contains a PyTorch-based deep learning project that trains a neural network to classify handwritten digit images (e.g., MNIST), and demonstrates adversarial attacks (e.g., FGSM) that exploit model vulnerabilities by subtly modifying inputs to fool the classifier.
ğŸ” Project Overview

    Image Classifier
    A convolutional neural network (CNN) that learns to classify digit images from the MNIST dataset.

    Adversarial Attack Generator
    Implementation of the Fast Gradient Sign Method (FGSM) to generate adversarial examples that reduce classification accuracy.

ğŸ“‚ Contents

.
â”œâ”€â”€ classifier.py         # Model definition & training
â”œâ”€â”€ attack.py             # Adversarial attack logic
â”œâ”€â”€ test.py               # Evaluation on clean and adversarial data
â”œâ”€â”€ utils.py              # Utility functions for visualization, loading, etc.
â”œâ”€â”€ README.md             # Project documentation
â””â”€â”€ requirements.txt      # Required dependencies

ğŸ§ª Features

    Simple, modular CNN architecture for number classification

    Training and testing on MNIST dataset

    Adversarial attack implementation (FGSM)

    Accuracy comparison between clean and adversarial inputs

    Visual inspection of perturbed images
